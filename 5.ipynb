{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb3AtndSJ5vF"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/y-akbal/Tedu_Computational_Statistics/blob/main/6/W6ALE.ipynb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mEApmbTYKNBh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy import stats\n",
        "import pickle\n",
        "from typing import Callable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buCSNqnDYqDM"
      },
      "source": [
        "# 1) Consider $\\int_0^{0.5} xe^{-x} dx$.\n",
        "# Compute a Monte Carlo estimate $\\hat{\\theta}$ by sampling from $U(0,0.5)$.\n",
        "# Find another Monte Carlo estimate $\\theta^{\\star}$ by sampling from exponential distribution. Which of the variances is smaller?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PmntRApcYpa9"
      },
      "outputs": [],
      "source": [
        "### Graded Cell A1\n",
        "### implement f(x) = xe^{-x}\n",
        "f = lambda x: x * np.exp(-x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w3QTXXXdU9Yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483f4a93-8277-48e0-9c2b-e6038583e7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are doin' good buddy go ahed\n"
          ]
        }
      ],
      "source": [
        "### Let's give a try:\n",
        "assert f(0) == 0 and np.isclose(np.exp(-1), f(1)) and np.isclose(-np.exp(1), f(-1)), \"Check your implementation mate\"\n",
        "print(\"You are doin' good buddy go ahed\")\n",
        "L = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "S0L9wT6KVce-"
      },
      "outputs": [],
      "source": [
        "def monte_carlo(f: Callable, n_sample=1000, seed=10) -> tuple:\n",
        "    np.random.seed(seed)  ### this is for reproducibility, do not delete it!!!\n",
        "    ### Your code here\n",
        "    samples = np.random.uniform(0, 0.5, n_sample)\n",
        "    values = f(samples)\n",
        "\n",
        "    approximation = np.mean(values) * 0.5  # Monte Carlo estimate\n",
        "\n",
        "    variance = np.var(values) / n_sample  # Variance estimate\n",
        "\n",
        "    return approximation, variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "iRbBxf09XCuD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8ff5b1-0c56-4b93-df0c-4db86f59fced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are doin' good buddy go ahead!!!\n"
          ]
        }
      ],
      "source": [
        "### Let's give a try:\n",
        "test = lambda x: x\n",
        "assert callable(monte_carlo), \"No way check your implementation 0\"\n",
        "assert np.isclose(monte_carlo(test)[0], 0.125, atol = 0.01), \" Check your implementation, this dude should be callable!!!\"\n",
        "assert np.isclose(monte_carlo(f)[0], 0.09, atol = 0.01),  \" Check your implementation (in particular mean)\"\n",
        "assert np.isclose(monte_carlo(f)[1], 0.007, atol = 0.1), \"Check your implementation (in particular variance)\"\n",
        "print(\"You are doin' good buddy go ahead!!!\")\n",
        "L_ = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ppVU8dLpYaij"
      },
      "outputs": [],
      "source": [
        "### Directly implement the integral by means of sampling from exponential distribution\n",
        "### Graded Cell A26\n",
        "### the function should return approximate value of integral and variance of the sample in a tuple (mind the order).\n",
        "def integration_expo(n_sample = 1000, seed = 10)-> tuple:\n",
        "  np.random.seed(10) ### this is for reproducability, do not delete it!!!\n",
        "  ### Your code here\n",
        "  samples = np.random.exponential(scale=1, size=n_sample)\n",
        "  values = f(samples)\n",
        "  approximation = np.mean(values) * 0.5  # Monte Carlo estimate\n",
        "\n",
        "  variance = np.var(values) / n_sample  # Variance estimate\n",
        "\n",
        "  return approximation, variance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "5QKv0Zj0emUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904a96f9-7468-41b9-d283-9b5fa721bc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are doin' good buddy go ahead!!!\n"
          ]
        }
      ],
      "source": [
        "### Let's give it a try:\n",
        "assert callable(integration_expo), \"No way check your implementation 0\"\n",
        "assert np.isclose(integration_expo()[0], 0.09, atol = 0.1), \" Check your implementation (in particular mean)\"\n",
        "assert np.isclose(integration_expo()[1], 0.02, atol = 0.1), \"Check your implementation(in particular variance)\"\n",
        "print(\"You are doin' good buddy go ahead!!!\")\n",
        "L__ = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vhtjBXAzgV_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d611c03a-e18e-4ad9-b72d-74964da55740"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Which sampling method has lesser variance? (First or Second):First\n",
            "Yeaaah you got it right buddy\n"
          ]
        }
      ],
      "source": [
        "### Graded Cell A15:\n",
        "### Run this cell and get your freedom.\n",
        "def set_answer():\n",
        "  global L___\n",
        "  while True:\n",
        "    res = input(\"Which sampling method has lesser variance? (First or Second):\")\n",
        "    if res == \"First\":\n",
        "      L___ = True\n",
        "      print(\"Yeaaah you got it right buddy\")\n",
        "      break\n",
        "    elif res == \"Second\":\n",
        "      L___ = False\n",
        "      break\n",
        "    else:\n",
        "      print(\"Either write First or Second\")\n",
        "set_answer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kI6npyIWfoCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbcf8511-54f9-43c8-d3b7-3d07fec5ddd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congrats comrade!!! You passed this assignment\n"
          ]
        }
      ],
      "source": [
        "def final_check():\n",
        "  x = int(L+L_+L__+ L___)\n",
        "  if x == 4:\n",
        "    print(\"Congrats comrade!!! You passed this assignment\")\n",
        "  else:\n",
        "    print(\"Comrade do not stop now!!! check your implementations\")\n",
        "  return\n",
        "final_check()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}